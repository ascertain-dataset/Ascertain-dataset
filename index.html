<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>ASCERTAIN dataset</title>

    <!-- Bootstrap -->
    <!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" integrity="sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==" crossorigin="anonymous">

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

  </head>
  <body>
   
    <div class="container">

      <!-- page header -->
      <div class="page-header">
        <div class="row">
          <div class="col-md-8">
            <h1>ASCERTAIN Dataset <small>Details and Download</small></h1>
          </div>
<!--           <div class="col-md-4">
            <img src="uni_trento.jpg"> 
          </div> -->
        </div>
      </div>

      <!-- Nav tabs -->
      <ul class="nav nav-tabs" role="tablist">
        <li role="presentation" class="active"><a href="#Home" aria-controls="home" role="tab" data-toggle="tab">Home</a></li>
        <li role="presentation"><a href="#Description" aria-controls="Description" role="tab" data-toggle="tab">Description</a></li>
        <li role="presentation"><a href="#data" aria-controls="data" role="tab" data-toggle="tab">Collected data</a></li>
        <li role="presentation"><a href="#Contact" aria-controls="Contact" role="tab" data-toggle="tab">Contact</a></li>

      </ul>



      <!-- Tab panes -->
      <div class="tab-content">
        <div role="tabpanel" class="tab-pane active" id="Home">

          <!-- home -->
          <div class="row">
            <div class="col-md-8">
              <br>
              
                            <h4>Overview</h4>
              <p>In this work we present ASCERTAIN– a multimodal databa<b>AS</b>e for impli<b>C</b>it p<b>ER</b>sonali<b>T</b>y and <b>A</b>ffect recognit<b>I</b>o<b>N</b> using commercial physiological sensors. To our knowledge, ASCERTAIN is the first database to connect personality traits and emotional states via physiological responses. ASCERTAIN contains big-five personality scales and emotional self-ratings of 58 users along with synchronously recorded Electroencephalogram (EEG), Electrocardiogram (ECG), Galvanic Skin Response (GSR) and facial activity data, recorded using off-the-shelf sensors while viewing affective movie clips. We first examine relationships between users’ affective ratings and personality scales in the context of prior observations, and then study linear and non-linear physiological correlates of emotion and personality. Our analysis suggests that the emotion–personality relationship is better captured by non-linear rather than linear statistics. We finally attempt binary emotion and personality trait recognition using physiological features. Experimental results cumulatively confirm that personality differences are better revealed while comparing user responses to emotionally homogeneous videos, and above-chance recognition is achieved for both affective and personality dimensions. </p>

            <div class="jumbotron">
                <h2>ASCERTAIN-Dataset</h2>
                <p class="lead">You can access the dataset here</p>
                <p><a class="btn btn-lg btn-success" href="#data" data-toggle="tab" role="button">Access dataset</a></p>
              </div>
              <br>

            </div>

            <div class="col-md-4">
              <br><br>
              <img src="ASCERTAIN_dataset.png">
            </div>
          </div>
          
       

          <!-- ] Description -->
        </div>

        <div role="tabpanel" class="tab-pane" id="Description">

          <div class="row marketing">
            <div class="col-lg-8 col-sm-10">
              <br>
              <h2 class="box-title">Description</h2>

              <p class="box-title-level2">
                <br>

              <h4>Recorded persons:</h4>
              58 (37 male, 21 female), mean age = 30 years <br>
              <br>

              <h4>Employed stimuli:</h4>
              36 movie video clips selected in a prior study (explained in the paper), mean length = 80s std= 20s<br>
              <br>
              <h4>Synchronized recorded Data:</h4>
              
            
              <h5>Physiological Signal:</h5> 
              3-channels Electro-cardiogrm (ECG)<br> 
              Galvanic skin response (GSR)<br>
              Electroencephalography (EEG): single-dry EEG sensor Neuroskype<br>

              
              <h5>Face Response: </h5>
              Facial landmark trajectories (EMO)<br>
       <!--       <small>As proposed by: H. Joho, J. Staiano, N. Sebe, and J. M. Jose. Looking at the viewer: analysing facial activity to detect personal highlights of multimedia contents. Multimedia Tools Appl., 51(2):505–523, 2011</small> -->


              <h4>Data evaluation:</h4>
              Annotations for the quality of all data recorded from the four modalities (ECG, EEG, GSR, EMO).<br>


              <h4>User data:</h4>
              Personality scores for the Big 5 Personality traits: <br>
              Extraversion, Agreeableness, Conscientiousness, Emotional Stabily, Openness <br>
              Additionally ratings for 50 descriptive adjectives for each subject from which the personality trait scores are calculated <br>
              <br>
              Self reports (for 36 videos for 58 subjects each): <br>
              Arousal, Valence, Engagement, Liking, Familiarity

              
               
              </p>
              <br>
            

              <h4>To get access to the documentation of the data, please click <a href="ASCERTAIN_documentation.pdf" target="_blank"> here! </a> </h4>
              <br>
              <br>

            </div>
          </div>
              

         
           <!-- ] Data Access -->
        </div>
        <div role="tabpanel" class="tab-pane" id="data">

          <div class="row marketing">
            <div class="col-lg-8 col-sm-10">
              <br>
              <h2 class="box-title">Please Read Me!</h2>
              Please make sure that you consider the following hints before downloading the shared files:
              <br>
              <br>
              - The data is shared only for research purposes.
              <br>
              - Commercial-related use of the data is not permitted.
              <br>
              - If you use any part of the shared data in any report, please make sure that you cite the <a href="http://mhug.disi.unitn.it/wp-content/uploads/2015/papers/2015/ICMI2015_Julia.pdf" target="_blank">"ASCERTAIN Dataset paper"</a> in the report.
              <br>
              <br>
              Thanks for your consideration! 


              <br>
              <h2 class="box-title">Access Request</h2>
              We use the Google Drive service to share the <b>extracted features</b> and the <b>raw data</b>. To grant you an access to the (<b>extracted features</b> or/and the <b>raw</b>) data, a Google id associated with your identity is needed. Please check the End User License Agreement (EULA) for details.
              <br>

              The EULA should be <a href="ASCERTAIN_eula.pdf" target="_blank">downloaded</a>, printed, signed, scanned and returned via email to <font color="red"> ascertain.mhug [at] gmail [dot] com </font> with the subject line <b>"ASCERTAIN access request"</b>. Please state in your email your position and your institution. Please use your institutional email (i.e. not your Microsoft, Yahoo, etc account, unless of course you work in Microsoft, Yahoo) to submit your access request. 

              <b><p class="box-title" align="center"> <a href="ASCERTAIN_eula.pdf" target="_blank"> Download the EULA!</a> 
              </p></b>


              <h2 class="box-title">Shared Data</h2>

              <p class="box-title-level2">
              The Extracted Features that are explained in the paper and used for experimental analysis are shared <a href="https://drive.google.com/folderview?id=0B3U2ncIWmTZYUTFoU2lNek5lVVE&usp=sharing" target="_blank"> here</a>. Also the raw data from each clip and each modality can be accessed <a href="https://drive.google.com/folderview?id=0B3U2ncIWmTZYaFNSZTFkM3dPSk0&usp=sharing" target="_blank"> here. </a> We used MATLAB for signal analysis. The shared files have ".mat" extensions and can be read using MATLAB/OCTAVE.</p>
              <br>
            
              <h4>To get access to the data documentations, please click <a href="ASCERTAIN_documentation.pdf" target="_blank"> here! </a> </h4>
              <h4>Here you can download the <a href="https://drive.google.com/folderview?id=0B3U2ncIWmTZYUTFoU2lNek5lVVE&usp=sharing" target="_blank"> Extracted Features</a> and the<a href="https://drive.google.com/folderview?id=0B3U2ncIWmTZYaFNSZTFkM3dPSk0&usp=sharing" target="_blank"> Raw Data. </a> </h4>
              <br>
              <br>


            </div>
          </div>
        </div>

         <!-- ] Contact -->
        <div role="tabpanel" class="tab-pane" id="Contact">
          <br>

             <h4>Contact Information</h4>
             <p>If you have any further questions about the dataset please contact:<br>
              <font color="red"> ascertain.mhug [at] gmail [dot] com </font> </p>

        </div>
      </div>


      <!-- <footer class="footer">
        <p>&copy; University of Trento</p>
      </footer> -->

    </div> <!-- /container -->

  </body>
</html>


